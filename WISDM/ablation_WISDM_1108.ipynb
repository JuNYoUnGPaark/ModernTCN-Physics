{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c37b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "================================================================================\n",
      "Loaded WISDM dataset (single txt)\n",
      "  X shape       : (27108, 80, 3)  (N, T, C)\n",
      "  y shape       : (27108,)  (N,)\n",
      "  subjects shape: (27108,) (N,)\n",
      "  unique subjects: [np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14), np.int64(15), np.int64(16), np.int64(17), np.int64(18), np.int64(19), np.int64(20), np.int64(21), np.int64(22), np.int64(23), np.int64(24), np.int64(25), np.int64(26), np.int64(27), np.int64(28), np.int64(29), np.int64(30), np.int64(31), np.int64(32), np.int64(33), np.int64(34), np.int64(35), np.int64(36)]\n",
      "================================================================================\n",
      "Num classes (WISDM): 6\n",
      "Total samples: 27108\n",
      "Splitting into 18975 train and 8133 test samples (Randomly).\n",
      "Train samples: 18975\n",
      "Test samples : 8133\n",
      "\n",
      "Train set label distribution (after random split):\n",
      "0    1790\n",
      "1    5930\n",
      "2     992\n",
      "3     857\n",
      "4    2127\n",
      "5    7279\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Resampled train samples: 5142\n",
      "\n",
      "Original label distribution (Train):\n",
      "0    1790\n",
      "1    5930\n",
      "2     992\n",
      "3     857\n",
      "4    2127\n",
      "5    7279\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resampled label distribution (Train):\n",
      "0    857\n",
      "1    857\n",
      "2    857\n",
      "3    857\n",
      "4    857\n",
      "5    857\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 1: Base (n_layers=3, Multi-scale, No SE)\n",
      "============================================================\n",
      "  - Parameters: 70,790\n",
      "[Model 1 (Base, L=3)] Epoch 25/150: Train Acc=96.43%, Test F1=0.8797, Test Acc=88.49% (Best F1: 0.9261, Best Acc: 94.22%)\n",
      "[Model 1 (Base, L=3)] Epoch 50/150: Train Acc=97.97%, Test F1=0.9120, Test Acc=91.80% (Best F1: 0.9389, Best Acc: 95.18%)\n",
      "[Model 1 (Base, L=3)] Epoch 75/150: Train Acc=98.81%, Test F1=0.9276, Test Acc=93.62% (Best F1: 0.9494, Best Acc: 96.36%)\n",
      "[Model 1 (Base, L=3)] Epoch 100/150: Train Acc=99.16%, Test F1=0.9287, Test Acc=94.21% (Best F1: 0.9494, Best Acc: 96.36%)\n",
      "[Model 1 (Base, L=3)] Epoch 125/150: Train Acc=99.34%, Test F1=0.9458, Test Acc=95.46% (Best F1: 0.9494, Best Acc: 96.36%)\n",
      "[Model 1 (Base, L=3)] Epoch 150/150: Train Acc=99.36%, Test F1=0.9399, Test Acc=95.01% (Best F1: 0.9494, Best Acc: 96.36%)\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 2: + SE Block\n",
      "============================================================\n",
      "  - Parameters: 72,402\n",
      "[Model 2 (+SE)] Epoch 25/150: Train Acc=96.25%, Test F1=0.8941, Test Acc=90.73% (Best F1: 0.9093, Best Acc: 92.95%)\n",
      "[Model 2 (+SE)] Epoch 50/150: Train Acc=97.87%, Test F1=0.9327, Test Acc=94.80% (Best F1: 0.9420, Best Acc: 95.50%)\n",
      "[Model 2 (+SE)] Epoch 75/150: Train Acc=98.93%, Test F1=0.9390, Test Acc=95.38% (Best F1: 0.9454, Best Acc: 96.00%)\n",
      "[Model 2 (+SE)] Epoch 100/150: Train Acc=99.12%, Test F1=0.9411, Test Acc=95.28% (Best F1: 0.9507, Best Acc: 96.03%)\n",
      "[Model 2 (+SE)] Epoch 125/150: Train Acc=99.43%, Test F1=0.9432, Test Acc=95.32% (Best F1: 0.9507, Best Acc: 96.05%)\n",
      "[Model 2 (+SE)] Epoch 150/150: Train Acc=99.20%, Test F1=0.9475, Test Acc=95.99% (Best F1: 0.9507, Best Acc: 96.08%)\n",
      "\n",
      "============================================================\n",
      "üî¨ Ablation 3: + SE Block + Physics Loss\n",
      "============================================================\n",
      "  - Parameters: 74,581\n",
      "[Physics*] Epoch 025/150 | Train Acc=96.39% | CE=0.3387 | Phys=0.0338 (Œª_total=0.050) | Total=0.3404 || Test F1=0.9141 | Test Acc=92.91% (Best F1=0.9209, Best Acc=94.05%)\n",
      "[Physics*] Epoch 050/150 | Train Acc=97.75% | CE=0.3028 | Phys=0.0338 (Œª_total=0.050) | Total=0.3044 || Test F1=0.9404 | Test Acc=95.43% (Best F1=0.9446, Best Acc=95.66%)\n",
      "[Physics*] Epoch 075/150 | Train Acc=98.81% | CE=0.2784 | Phys=0.0339 (Œª_total=0.050) | Total=0.2801 || Test F1=0.9440 | Test Acc=95.84% (Best F1=0.9479, Best Acc=96.29%)\n",
      "[Physics*] Epoch 100/150 | Train Acc=99.04% | CE=0.2697 | Phys=0.0338 (Œª_total=0.050) | Total=0.2714 || Test F1=0.9440 | Test Acc=95.93% (Best F1=0.9539, Best Acc=96.46%)\n",
      "[Physics*] Epoch 125/150 | Train Acc=99.32% | CE=0.2630 | Phys=0.0338 (Œª_total=0.050) | Total=0.2647 || Test F1=0.9524 | Test Acc=96.24% (Best F1=0.9560, Best Acc=96.66%)\n",
      "[Physics*] Epoch 150/150 | Train Acc=99.28% | CE=0.2640 | Phys=0.0338 (Œª_total=0.050) | Total=0.2657 || Test F1=0.9518 | Test Acc=96.48% (Best F1=0.9567, Best Acc=96.68%)\n",
      "\n",
      "==========================================================================================\n",
      "Ablation Study ÏµúÏ¢Ö ÏöîÏïΩ (n_layers=3 Í∏∞Ï§Ä)\n",
      "==========================================================================================\n",
      "Model                               |              Best Test F1 |         Best Test Acc (%)\n",
      "-----------------------------------------------------------------------------------------\n",
      "1. Base (L=3, Multi)                |                    0.9494 |                     96.36\n",
      "2. + SE Block                       |                    0.9507 |                     96.08\n",
      "3. + Physics Loss                   |                    0.9567 |                     96.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from pathlib import Path\n",
    "import time\n",
    "import random\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt    \n",
    "from sklearn.metrics import f1_score    \n",
    "\n",
    "# ========================\n",
    "# SEED Í≥†Ï†ï Ìï®Ïàò\n",
    "# ========================\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"42\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # CUDA 11+\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(True, warn_only=False)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ========================\n",
    "# WISDM Îç∞Ïù¥ÌÑ∞ Î°úÎìú \n",
    "# ========================\n",
    "class WISDMDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Îã®Ïùº WISDM txt ÌòïÏãù:\n",
    "    subject,activity,timestamp,x,y,z;\n",
    "    Ïòà) 33,Jogging,49105962326000,-0.6946377,12.680544,0.50395286;\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str, window_size: int = 80, step_size: int = 40):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "\n",
    "        if not os.path.isfile(file_path):\n",
    "            raise FileNotFoundError(f\"WISDM txt file not found: {file_path}\")\n",
    "\n",
    "        df = self._load_file(file_path)\n",
    "        self.X, self.y, self.subjects = self._create_windows(df)\n",
    "\n",
    "        self.unique_subjects = sorted(np.unique(self.subjects))\n",
    "\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Loaded WISDM dataset (single txt)\")\n",
    "        print(f\"  X shape       : {self.X.shape}  (N, T, C)\")\n",
    "        print(f\"  y shape       : {self.y.shape}  (N,)\")\n",
    "        print(f\"  subjects shape: {self.subjects.shape} (N,)\")\n",
    "        print(f\"  unique subjects: {self.unique_subjects}\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    def _load_file(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"ÏõêÎ≥∏ txt Ìïú Í∞úÎ•º ÌÜµÏß∏Î°ú ÏùΩÏñ¥ÏÑú DataFrameÏúºÎ°ú Î≥ÄÌôò.\"\"\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        rows = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # ÎÅù ÏÑ∏ÎØ∏ÏΩúÎ°† Ï†úÍ±∞\n",
    "            line = line.replace(\";\", \"\")\n",
    "            parts = line.split(\",\")\n",
    "\n",
    "            # subject, activity, timestamp, x, y, z ‚Üí 6Í∞ú ÏïÑÎãàÎ©¥ Ïä§ÌÇµ\n",
    "            if len(parts) != 6:\n",
    "                continue\n",
    "\n",
    "            subj, act, ts, x, y, z = parts\n",
    "\n",
    "            # x,y,z Ï§ë ÌïòÎÇòÎùºÎèÑ ÎπÑÏñ¥ÏûàÏúºÎ©¥ Ïä§ÌÇµ\n",
    "            if x.strip() == \"\" or y.strip() == \"\" or z.strip() == \"\":\n",
    "                continue\n",
    "\n",
    "            rows.append([subj, act, ts, x, y, z])\n",
    "\n",
    "        if not rows:\n",
    "            raise ValueError(f\"No valid rows parsed from file: {file_path}\")\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=[\"subject\", \"activity\", \"timestamp\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "        # Î¨∏ÏûêÏó¥ ‚Üí NaN Ï≤òÎ¶¨ ÌõÑ Ïà´ÏûêÎ°ú Î≥ÄÌôò\n",
    "        df = df.replace([\"\", \"NaN\", \"nan\"], np.nan).dropna(subset=[\"subject\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "        df[\"subject\"] = pd.to_numeric(df[\"subject\"], errors=\"coerce\")\n",
    "        df[\"x\"] = pd.to_numeric(df[\"x\"], errors=\"coerce\")\n",
    "        df[\"y\"] = pd.to_numeric(df[\"y\"], errors=\"coerce\")\n",
    "        df[\"z\"] = pd.to_numeric(df[\"z\"], errors=\"coerce\")\n",
    "\n",
    "        df = df.dropna(subset=[\"subject\", \"x\", \"y\", \"z\"])\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\"After cleaning, WISDM DataFrame is empty. Check file format.\")\n",
    "\n",
    "        df[\"subject\"] = df[\"subject\"].astype(int)\n",
    "\n",
    "        # activity Î¨∏ÏûêÏó¥ ‚Üí Ï†ïÏàò ÎùºÎ≤®\n",
    "        df[\"activity_id\"] = df[\"activity\"].astype(\"category\").cat.codes\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _create_windows(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        subject Î≥ÑÎ°ú ÎÇòÎà†ÏÑú sliding window ÏÉùÏÑ±.\n",
    "        X: (N, T, 3), y: (N,), subjects: (N,)\n",
    "        \"\"\"\n",
    "        X_list, y_list, s_list = [], [], []\n",
    "\n",
    "        for subj_id in sorted(df[\"subject\"].unique()):\n",
    "            df_sub = df[df[\"subject\"] == subj_id]\n",
    "\n",
    "            # ÌïÑÏöîÌïòÎ©¥ Ïó¨Í∏∞ÏÑú activityÎ≥ÑÎ°úÎèÑ ÎÅäÏùÑ Ïàò ÏûàÏùå (ÏõêÌïòÎ©¥ ÌôïÏû• Í∞ÄÎä•)\n",
    "            data = df_sub[[\"x\", \"y\", \"z\"]].to_numpy(dtype=np.float32)      # (L, 3)\n",
    "            labels = df_sub[\"activity_id\"].to_numpy(dtype=np.int64)        # (L,)\n",
    "            L = len(df_sub)\n",
    "\n",
    "            start = 0\n",
    "            while start + self.window_size <= L:\n",
    "                end = start + self.window_size\n",
    "\n",
    "                window_x = data[start:end]          # (T, 3)\n",
    "                window_y = labels[end - 1]          # ÎßàÏßÄÎßâ ÌÉÄÏûÑÏä§ÌÖù ÎùºÎ≤®\n",
    "\n",
    "                X_list.append(window_x.T)           # (3, T)\n",
    "                y_list.append(window_y)\n",
    "                s_list.append(subj_id)\n",
    "\n",
    "                start += self.step_size\n",
    "\n",
    "        if len(X_list) == 0:\n",
    "            raise ValueError(\"[WISDMDataset] No windows created. Try smaller window_size or check data.\")\n",
    "\n",
    "        X = np.stack(X_list, axis=0).astype(np.float32)  # (N, 3, T)\n",
    "        y = np.array(y_list, dtype=np.int64)\n",
    "        s = np.array(s_list, dtype=np.int64)\n",
    "\n",
    "        # (N, 3, T) ‚Üí (N, T, 3)\n",
    "        X = X.transpose(0, 2, 1)\n",
    "        return X, y, s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        return (\n",
    "            torch.FloatTensor(self.X[idx]),          # (T, 3)\n",
    "            torch.LongTensor([self.y[idx]])[0],\n",
    "            self.subjects[idx],\n",
    "        )\n",
    "\n",
    "# ========================\n",
    "# üî• Modern TCN Components \n",
    "# ========================\n",
    "class DepthwiseSeparableConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(\n",
    "            in_channels, in_channels, kernel_size,\n",
    "            padding=padding, dilation=dilation, groups=in_channels\n",
    "        )\n",
    "        self.pointwise = nn.Conv1d(in_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class MultiScaleConvBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_sizes=[3, 5, 7], dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k in kernel_sizes:\n",
    "            padding = ((k - 1) * dilation) // 2\n",
    "            branch = nn.ModuleDict({\n",
    "                'conv': DepthwiseSeparableConv1d(channels, channels, k, dilation, padding),\n",
    "                'norm': nn.BatchNorm1d(channels),\n",
    "                'dropout': nn.Dropout(dropout)\n",
    "            })\n",
    "            self.branches.append(branch)\n",
    "        self.fusion = nn.Conv1d(channels * len(kernel_sizes), channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        target_length = x.size(2)\n",
    "        for branch in self.branches:\n",
    "            out = branch['conv'](x)\n",
    "            if out.size(2) != target_length:\n",
    "                out = out[:, :, :target_length]\n",
    "            out = branch['norm'](out)\n",
    "            out = F.gelu(out)\n",
    "            out = branch['dropout'](out)\n",
    "            outputs.append(out)\n",
    "        multi_scale = torch.cat(outputs, dim=1)\n",
    "        return self.fusion(multi_scale)\n",
    "\n",
    "class ModernTCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 7], dilation=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # NOTE: kernel_sizesÍ∞Ä [7]Ï≤òÎüº Îã®Ïùº Î¶¨Ïä§Ìä∏Î°ú Îì§Ïñ¥Ïò§Î©¥ Single-scaleÏù¥ Îê®\n",
    "        self.multi_conv1 = MultiScaleConvBlock(\n",
    "            in_channels if in_channels == out_channels else out_channels,\n",
    "            kernel_sizes, dilation, dropout\n",
    "        )\n",
    "        \n",
    "        # NOTE: kernel_sizes Ï§ë Í∞ÄÏû• ÌÅ∞ Í∞íÏùÑ Í∏∞Ï§ÄÏúºÎ°ú padding\n",
    "        max_k = max(kernel_sizes) if isinstance(kernel_sizes, list) else kernel_sizes\n",
    "        padding = ((max_k - 1) * dilation) // 2\n",
    "        \n",
    "        self.conv2 = DepthwiseSeparableConv1d(\n",
    "            out_channels, out_channels, max_k, dilation, padding\n",
    "        )\n",
    "        self.norm2 = nn.BatchNorm1d(out_channels)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        target_length = x.size(2)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "            residual = x\n",
    "        \n",
    "        out = self.multi_conv1(x)\n",
    "        if out.size(2) != target_length:\n",
    "            out = out[:, :, :target_length]\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        if out.size(2) != target_length:\n",
    "            out = out[:, :, :target_length]\n",
    "        out = self.norm2(out)\n",
    "        out = F.gelu(out)\n",
    "        out = self.dropout2(out)\n",
    "        return F.gelu(out + residual)\n",
    "\n",
    "class SqueezeExcitation1d(nn.Module):\n",
    "    def __init__(self, channels, reduction=5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "    def forward(self, x):\n",
    "        batch, channels, _ = x.size()\n",
    "        squeeze = F.adaptive_avg_pool1d(x, 1).view(batch, channels)\n",
    "        excitation = F.relu(self.fc1(squeeze))\n",
    "        excitation = torch.sigmoid(self.fc2(excitation)).view(batch, channels, 1)\n",
    "        return x * excitation\n",
    "\n",
    "class LargeKernelConv1d(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=21):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.depthwise = nn.Conv1d(\n",
    "            channels, channels, kernel_size,\n",
    "            padding=padding, groups=channels\n",
    "        )\n",
    "        self.norm = nn.BatchNorm1d(channels)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "# ========================\n",
    "# Modern TCN Base Î™®Îç∏ \n",
    "# ========================\n",
    "class BaseModernTCNHAR(nn.Module):\n",
    "    def __init__(self, input_dim=9, hidden_dim=128, n_layers=4, n_classes=6,\n",
    "                 kernel_sizes=[3, 7], large_kernel=21, dropout=0.1, use_se=True):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv1d(input_dim, hidden_dim, 1)\n",
    "        self.large_kernel_conv = LargeKernelConv1d(hidden_dim, large_kernel)\n",
    "        self.tcn_blocks = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            dilation = 2 ** i\n",
    "            self.tcn_blocks.append(\n",
    "                ModernTCNBlock(\n",
    "                    hidden_dim, hidden_dim,\n",
    "                    kernel_sizes=kernel_sizes,\n",
    "                    dilation=dilation,\n",
    "                    dropout=dropout\n",
    "                )\n",
    "            )\n",
    "        self.final_large_kernel = LargeKernelConv1d(hidden_dim, large_kernel)\n",
    "        # self.final_large_kernel = nn.Identity()\n",
    "        self.use_se = use_se\n",
    "        if use_se:\n",
    "            self.se = SqueezeExcitation1d(hidden_dim)\n",
    "        self.norm_final = nn.LayerNorm(hidden_dim)\n",
    "        self.head = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.input_proj(x)\n",
    "        x = self.large_kernel_conv(x)\n",
    "        x = F.gelu(x)\n",
    "        for block in self.tcn_blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_large_kernel(x)\n",
    "        x = F.gelu(x)\n",
    "        if self.use_se:\n",
    "            x = self.se(x)\n",
    "        x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "        x = self.norm_final(x)\n",
    "        return self.head(x)\n",
    "\n",
    "# ========================\n",
    "# Physics-Guided Modern TCN HAR \n",
    "# ========================\n",
    "class PhysicsModernTCNHAR(BaseModernTCNHAR):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        hidden_dim = self.head.in_features\n",
    "\n",
    "        self.gravity_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_gravity=False):\n",
    "        x = x.transpose(1, 2)\n",
    "        x_feat = self.input_proj(x)\n",
    "        x_feat = F.gelu(self.large_kernel_conv(x_feat))\n",
    "        for block in self.tcn_blocks:\n",
    "            x_feat = block(x_feat)\n",
    "        x_feat = F.gelu(self.final_large_kernel(x_feat))\n",
    "        if self.use_se:\n",
    "            x_feat = self.se(x_feat)\n",
    "\n",
    "        pooled = F.adaptive_avg_pool1d(x_feat, 1).squeeze(-1)\n",
    "        pooled = self.norm_final(pooled)\n",
    "        logits = self.head(pooled)\n",
    "\n",
    "        outs = [logits]\n",
    "\n",
    "        if return_gravity:\n",
    "            seq_feat = x_feat.transpose(1, 2)  # (B,T,C)\n",
    "            gvec = self.gravity_head(seq_feat)   # (B,T,3)\n",
    "            outs.append(gvec)\n",
    "\n",
    "        return tuple(outs) if len(outs) > 1 else outs[0]\n",
    "\n",
    "# ========================\n",
    "# Physics Loss (acc-only)\n",
    "# ========================\n",
    "def fir_lpf_hann_bt3(x,K=31):\n",
    "    B,T,C = x.shape\n",
    "\n",
    "    xc = x.transpose(1,2)\n",
    "\n",
    "    w = torch.hann_window(K, device=x.device, dtype=x.dtype)\n",
    "    w = (w/w.sum()).view(1,1,-1).expand(C,1,-1)\n",
    "\n",
    "    a_lp = F.conv1d(xc,w,padding=K//2,groups=C).transpose(1,2)\n",
    "\n",
    "    return a_lp, x - a_lp\n",
    "\n",
    "def unit_norm(v,eps=1e-8): return v/(v.norm(dim=-1,keepdim=True)+eps)\n",
    "\n",
    "def diff1(x): d=x[:,1:]-x[:,:-1]; return torch.cat([torch.zeros_like(d[:,:1]),d],1)\n",
    "\n",
    "def physics_loss_wisdm(X_raw,g_pred,lambdas,params):\n",
    "    acc = X_raw[:,:,:3]\n",
    "    eps=1e-8\n",
    "    a_lp,a_hp = fir_lpf_hann_bt3(acc,K=params.get(\"K\",31))\n",
    "\n",
    "    g_from_acc = unit_norm(a_lp,eps)\n",
    "    g_pred = unit_norm(g_pred,eps)\n",
    "\n",
    "    acc_norm=acc.norm(-1)\n",
    "    hp_norm=a_hp.norm(-1)\n",
    "\n",
    "    g0=params.get(\"g0\",1.0)\n",
    "\n",
    "    tau_a=params.get(\"tau_a\",0.5)\n",
    "    tau_g=params.get(\"tau_g\",0.3)\n",
    "\n",
    "    gate=((hp_norm<tau_a)&((acc_norm-g0).abs()<tau_g)).float()\n",
    "    gate_sum=gate.sum()+1e-6\n",
    "\n",
    "    cos=(g_from_acc*g_pred).sum(-1).clamp(-1+1e-6,1-1e-6)\n",
    "\n",
    "    L_grav=(gate*torch.acos(cos)).sum()/gate_sum\n",
    "    L_gmag=(gate*(acc_norm-g0).pow(2)).sum()/gate_sum\n",
    "\n",
    "    a_body=acc-g0*g_pred\n",
    "    win=params.get(\"win_mean\",24)\n",
    "    a_body_m=fir_lpf_hann_bt3(a_body,K=max(3,2*(win//2)+1))[0]\n",
    "\n",
    "    L_split=(gate*a_body_m.norm(-1)).sum()/gate_sum\n",
    "    L_smooth=diff1(acc).pow(2).sum(-1).mean()\n",
    "\n",
    "    dt=params.get(\"dt\",1/20)\n",
    "    dg=diff1(g_pred)/max(dt,1e-3)\n",
    "\n",
    "    L_static=(gate*dg.norm(-1)).sum()/gate_sum\n",
    "    L=(lambdas.get(\"grav\",.2)*L_grav+\n",
    "       lambdas.get(\"gmag\",.05)*L_gmag+\n",
    "       lambdas.get(\"split\",.15)*L_split+\n",
    "       lambdas.get(\"smooth\",.02)*L_smooth+\n",
    "       lambdas.get(\"static\",.05)*L_static)\n",
    "    \n",
    "    return L,dict(grav=L_grav.item(),gmag=L_gmag.item(),split=L_split.item(),smooth=L_smooth.item(),static=L_static.item())\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Ìó¨Ìçº: ÌååÎùºÎØ∏ÌÑ∞ Ïπ¥Ïö¥Ìä∏\n",
    "# ========================\n",
    "def get_n_params(model):\n",
    "    return f\"{sum(p.numel() for p in model.parameters() if p.requires_grad):,}\"\n",
    "\n",
    "# ========================\n",
    "# 'Í∏∞Î≥∏' ÌïôÏäµ Ìï®Ïàò (F1 Score Í∏∞Ï§Ä)\n",
    "# ========================\n",
    "def train_base(model, train_loader, test_loader, device, epochs, model_name=\"Base\"):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    best_f1 = 0.0\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # --- Í∏∞Î≥∏ ÌïôÏäµ (Physics Loss ÏóÜÏùå) ---\n",
    "            logits = model(X)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            # ------------------------------------\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_correct, test_total = 0, 0\n",
    "        all_preds = [] \n",
    "        all_y = []  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y, _ in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                \n",
    "                # --- Í∏∞Î≥∏ Ï∂îÎ°† ---\n",
    "                logits = model(X)\n",
    "                # -----------------\n",
    "                \n",
    "                preds = logits.argmax(1)\n",
    "\n",
    "                test_correct += (preds == y).sum().item() \n",
    "                test_total += y.size(0)           \n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_y.extend(y.cpu().numpy())\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        test_f1 = f1_score(all_y, all_preds, average='macro')\n",
    "        test_acc = 100 * test_correct / test_total\n",
    "\n",
    "        best_f1 = max(best_f1, test_f1) \n",
    "        best_acc = max(best_acc, test_acc)\n",
    "\n",
    "        if (epoch + 1) % 25 == 0 or epoch == epochs - 1:\n",
    "            print(f'[{model_name}] Epoch {epoch+1:02d}/{epochs}: Train Acc={train_acc:.2f}%, Test F1={test_f1:.4f}, Test Acc={test_acc:.2f}% (Best F1: {best_f1:.4f}, Best Acc: {best_acc:.2f}%)')\n",
    "\n",
    "    return best_f1, best_acc \n",
    "\n",
    "# ========================\n",
    "# 'Î¨ºÎ¶¨ Í∏∞Î∞ò' ÌïôÏäµ Ìï®Ïàò (F1 Score Í∏∞Ï§Ä)\n",
    "# ========================\n",
    "def train_physics(model, train_loader, test_loader, device, n_classes, epochs=50, lambda_phys=0.05, log_every=1):\n",
    "    \"\"\"\n",
    "    lambda_phys: Ï¥ù Î¨ºÎ¶¨ÏÜêÏã§ Ïä§ÏºÄÏùº (Í∞Å Ìï≠ ÏÉÅÎåÄÍ∞ÄÏ§ëÏπòÎäî ÎÇ¥Î∂Ä lambdas)\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    base_lambdas_wisdm = dict(\n",
    "        grav   = 0.20,\n",
    "        split  = 0.15,\n",
    "        gmag   = 0.05,\n",
    "        smooth = 0.02,\n",
    "        static = 0.05,\n",
    "    )\n",
    "\n",
    "    params_wisdm = dict(\n",
    "        tau_a    = 0.5,\n",
    "        tau_g    = 0.3,\n",
    "        win_mean = 24,\n",
    "        dt       = 1/20,   # WISDM ~20Hz\n",
    "        g0       = 1.0,\n",
    "        K        = 31,\n",
    "    )\n",
    "\n",
    "    best_f1 = best_acc = 0.0\n",
    "    history = {\"train_ce\": [], \"train_phys\": [], \"train_total\": [], \"test_acc\": [], \"test_f1\": []}\n",
    "\n",
    "    warm_epochs = 15\n",
    "    best_state = None\n",
    "    best_eval_cache = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        ce_sum = phys_sum = total_sum = 0.0\n",
    "        correct = total = 0\n",
    "\n",
    "        # warm-up Ïä§ÏºÄÏùº: Ï¥àÎ∞òÏóî Œª_physÎ•º ÏÑ†Ìòï Ï¶ùÍ∞Ä\n",
    "        if epoch <= warm_epochs:\n",
    "            phys_scale = lambda_phys * (epoch / warm_epochs)\n",
    "        else:\n",
    "            phys_scale = lambda_phys\n",
    "\n",
    "        for X, y, _ in train_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits, gvec = model(X, return_gravity=True)\n",
    "            loss_ce = F.cross_entropy(logits, y, label_smoothing=0.05)\n",
    "            L_phys, stats = physics_loss_wisdm(X, g_pred=gvec, lambdas=base_lambdas_wisdm, params=params_wisdm)\n",
    "\n",
    "            loss = loss_ce + phys_scale * L_phys\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            ce_sum += loss_ce.item(); phys_sum += L_phys.item(); total_sum += loss.item()\n",
    "            preds = logits.argmax(1); correct += (preds == y).sum().item(); total += y.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        n_batches = len(train_loader)\n",
    "        ce_avg, phys_avg, total_avg = ce_sum/n_batches, phys_sum/n_batches, total_sum/n_batches\n",
    "        train_acc = 100.0 * correct / total\n",
    "\n",
    "        # ===== ÌèâÍ∞Ä =====\n",
    "        model.eval()\n",
    "        test_correct = test_total = 0\n",
    "        all_preds, all_y = [], []\n",
    "        all_feats = []\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for X, y, _ in test_loader:\n",
    "                X, y = X.to(device), y.to(device)\n",
    "\n",
    "                feats = model.input_proj(X.transpose(1, 2))\n",
    "                feats = model.large_kernel_conv(feats)\n",
    "                feats = F.gelu(feats)\n",
    "                for block in model.tcn_blocks:\n",
    "                    feats = block(feats)\n",
    "                feats = model.final_large_kernel(feats)\n",
    "                feats = F.gelu(feats)\n",
    "                if model.use_se:\n",
    "                    feats = model.se(feats)\n",
    "                pooled = F.adaptive_avg_pool1d(feats, 1).squeeze(-1)\n",
    "                pooled = model.norm_final(pooled)\n",
    "\n",
    "                logits = model.head(pooled)\n",
    "                preds = logits.argmax(1)\n",
    "\n",
    "                test_correct += (preds == y).sum().item()\n",
    "                test_total   += y.size(0)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_y.extend(y.cpu().numpy())\n",
    "                all_feats.append(pooled.cpu().numpy())\n",
    "\n",
    "        test_acc = 100.0 * test_correct / test_total\n",
    "        test_f1 = f1_score(all_y, all_preds, labels=list(range(n_classes)), average='macro', zero_division=0)\n",
    "        best_acc = max(best_acc, test_acc)\n",
    "\n",
    "        if test_f1 > best_f1 + 1e-9:\n",
    "            best_f1 = test_f1\n",
    "            best_acc = max(best_acc, test_acc)\n",
    "            # CPU ÌÖêÏÑúÎ°ú ÍπäÏùÄ Î≥µÏÇ¨\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            # Î≤†Ïä§Ìä∏ ÏãúÏ†ê Ï∫êÏãú Ï†ÄÏû•\n",
    "            best_eval_cache = {\n",
    "                \"y\":     np.array(all_y, dtype=np.int64),\n",
    "                \"preds\": np.array(all_preds, dtype=np.int64),\n",
    "                \"feats\": np.concatenate(all_feats, axis=0)  # (N, D)\n",
    "            }\n",
    "\n",
    "        history[\"train_ce\"].append(ce_avg); history[\"train_phys\"].append(phys_avg)\n",
    "        history[\"train_total\"].append(total_avg); history[\"test_acc\"].append(test_acc); history[\"test_f1\"].append(test_f1)\n",
    "\n",
    "        if (epoch % log_every) == 0:\n",
    "            print(f\"[Physics*] Epoch {epoch:03d}/{epochs} | Train Acc={train_acc:.2f}% | \"\n",
    "                  f\"CE={ce_avg:.4f} | Phys={phys_avg:.4f} (Œª_total={phys_scale:.3f}) | \"\n",
    "                  f\"Total={total_avg:.4f} || Test F1={test_f1:.4f} | Test Acc={test_acc:.2f}% \"\n",
    "                  f\"(Best F1={best_f1:.4f}, Best Acc={best_acc:.2f}%)\")\n",
    "\n",
    "    return best_f1, best_acc, history, best_state, best_eval_cache  \n",
    "\n",
    "\n",
    "# ========================\n",
    "# ÏãúÍ∞ÅÌôî Ìï®Ïàò\n",
    "# ========================\n",
    "def plot_results(results_dict):\n",
    "    print(\"\\n\" + \"=\"*90) # ‚≠êÔ∏è ÎÑàÎπÑ Ï°∞Ï†à\n",
    "    print(\"Ablation Study ÏµúÏ¢Ö ÏöîÏïΩ (n_layers=3 Í∏∞Ï§Ä)\")\n",
    "    print(\"=\"*90) # ‚≠êÔ∏è ÎÑàÎπÑ Ï°∞Ï†à\n",
    "    \n",
    "    print(f\"{'Model':<35} | {'Best Test F1':>25} | {'Best Test Acc (%)':>25}\")\n",
    "    print(\"-\" * 89) \n",
    "    \n",
    "    # ÎîïÏÖîÎÑàÎ¶¨ÏóêÏÑú F1Í≥º AccÎ•º Î™®Îëê Í∫ºÎÇ¥ÏÑú Ï∂úÎ†•\n",
    "    for name, metrics in results_dict.items():\n",
    "        print(f\"{name:<35} | {metrics['f1']:>25.4f} | {metrics['acc']:>25.2f}\")\n",
    "    print(\"-\" * 89)\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    # --- ÏãúÍ∞ÅÌôî (F1 Score Í∏∞Ï§Ä) ---\n",
    "    names = list(results_dict.keys())\n",
    "    scores_f1 = [metrics['f1'] for metrics in results_dict.values()]\n",
    "    \n",
    "    plt.figure(figsize=(8, 5)) # Í∑∏ÎûòÌîÑ ÌÅ¨Í∏∞ Ï°∞Ï†à\n",
    "    colors = ['#AEC7E8', '#98DF8A', '#FF9896'] # 3Í∞ÄÏßÄ ÏÉâÏÉÅ\n",
    "    bars = plt.bar(names, scores_f1, color=colors)\n",
    "    plt.ylabel('Best F1 Score (Macro)', fontsize=12)\n",
    "    plt.title('Ablation Study: Component Contribution (Base n_layers=3)', fontsize=14)\n",
    "    plt.xticks(rotation=0, ha='center')\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval + 0.005, f'{yval:.4f}', \n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "    min_score = min(scores_f1) if scores_f1 else 0.9 # ÏµúÏÜåÍ∞í 0.9Î°ú Í∞ÄÏ†ï\n",
    "    plt.ylim(bottom=max(0, min_score - 0.02), top=max(scores_f1) * 1.02 if scores_f1 else 1.0) \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# ========================\n",
    "# Î©îÏù∏ Ïã§Ìñâ Ìï®Ïàò (Ablation Study)\n",
    "# ========================\n",
    "def main():\n",
    "    set_seed(42) \n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    data_path = 'C://Users/park9/ModernTCN_Physics/data/WISDM_ar_v1.1_raw.txt'\n",
    "\n",
    "    try:\n",
    "        # UCIHARDataset ÎåÄÏã† WISDMDataset ÏÇ¨Ïö© (Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Ìïú Î≤àÏóê Î°úÎìú)\n",
    "        full_ds = WISDMDataset(data_path, window_size=80, step_size=40)  # ‚òÖ ÎÑ§Í∞Ä Ï†ïÏùòÌïú ÌååÎùºÎØ∏ÌÑ∞Ïóê ÎßûÏ∂∞ÏÑú\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. 'data_path' Î≥ÄÏàòÎ•º ÏàòÏ†ïÌïòÏÑ∏Ïöî.\")\n",
    "        print(f\"ÌòÑÏû¨ Í≤ΩÎ°ú: {data_path}\")\n",
    "        return\n",
    "    \n",
    "    # ==========================================================\n",
    "    # 2) ‚òÖ‚òÖ‚òÖ Random train/test split (Subject-agnostic) ‚òÖ‚òÖ‚òÖ\n",
    "    #    (Subject-wise Î∞è Undersampling Î°úÏßÅ Ï†úÍ±∞)\n",
    "    # ==========================================================\n",
    "    \n",
    "    N_CLASSES = len(np.unique(full_ds.y))\n",
    "    print(\"Num classes (WISDM):\", N_CLASSES)\n",
    "\n",
    "    # --- Random Split ÏÇ¨Ïö© ---\n",
    "    total_samples = len(full_ds)\n",
    "    train_ratio = 0.7\n",
    "    n_train_samples = int(total_samples * train_ratio)\n",
    "    n_test_samples = total_samples - n_train_samples\n",
    "\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Splitting into {n_train_samples} train and {n_test_samples} test samples (Randomly).\")\n",
    "\n",
    "    # Ïû¨ÌòÑ Í∞ÄÎä•ÌïòÎèÑÎ°ù generatorÎ°ú ÏãúÎìú Í≥†Ï†ï\n",
    "    generator = torch.Generator().manual_seed(42)\n",
    "    train_ds, test_ds = torch.utils.data.random_split(\n",
    "        full_ds, \n",
    "        [n_train_samples, n_test_samples], \n",
    "        generator=generator\n",
    "    )\n",
    "    # --- Î≥ÄÍ≤Ω ÏôÑÎ£å ---\n",
    "\n",
    "    print(f\"Train samples: {len(train_ds)}\")\n",
    "    print(f\"Test samples : {len(test_ds)}\")\n",
    "\n",
    "    # (ÏÑ†ÌÉù ÏÇ¨Ìï≠) Î∂ÑÌï†Îêú ÌïôÏäµÏÖãÏùò ÎùºÎ≤® Î∂ÑÌè¨ ÌôïÏù∏\n",
    "    print(\"\\nTrain set label distribution (after random split):\")\n",
    "    print(pd.Series(full_ds.y[train_ds.indices]).value_counts().sort_index())\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # ============================\n",
    "    # 3) train set ÌÜµÍ≥ÑÎ°ú Ï†ïÍ∑úÌôî\n",
    "    # ============================\n",
    "    # (random_splitÏù¥ Î∞òÌôòÌïòÎäî train_dsÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§)\n",
    "    def compute_train_stats(subset):\n",
    "        X_train = torch.from_numpy(subset.dataset.X[subset.indices]).float()\n",
    "        mean = X_train.mean(dim=(0, 1), keepdim=True)\n",
    "        std  = X_train.std(dim=(0, 1), keepdim=True).clamp_min(1e-6)\n",
    "        return mean, std\n",
    "\n",
    "    mean, std = compute_train_stats(train_ds)\n",
    "\n",
    "    # ============================\n",
    "    # 4) DataLoaders ÏÉùÏÑ±\n",
    "    # ============================\n",
    "    def make_loaders(train_ds, test_ds, mean, std, batch_size=64, seed=42):\n",
    "        def collate_norm(batch):\n",
    "            X, y, s = zip(*batch)\n",
    "            X = torch.stack(X, dim=0).float()      # (B, T, C)\n",
    "            X = (X - mean) / std                   # ‚òÖ z-score Ï†ïÍ∑úÌôî\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "            s = torch.tensor(s, dtype=torch.long)\n",
    "            return X, y, s\n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, batch_size=batch_size, shuffle=True, # ‚òÖ random split Îêú train_ds\n",
    "            generator=g, num_workers=0, drop_last=True,\n",
    "            pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_ds, batch_size=batch_size, shuffle=False, # ‚òÖ random split Îêú test_ds\n",
    "            num_workers=0, drop_last=False,\n",
    "            pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "        )\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    # ‚òÖ‚òÖ‚òÖ random splitÏúºÎ°ú ÎÇòÎâú train_ds, test_dsÎ°ú Î°úÎçî ÏÉùÏÑ± ‚òÖ‚òÖ‚òÖ\n",
    "    train_loader, test_loader = make_loaders(train_ds, test_ds, mean, std, seed=42)\n",
    "    # ============================\n",
    "    # 3) train set ÌÜµÍ≥ÑÎ°ú Ï†ïÍ∑úÌôî\n",
    "    # ============================\n",
    "    def compute_train_stats(subset):\n",
    "        # subset.dataset.X: (N_total, T, C)\n",
    "        X_train = torch.from_numpy(subset.dataset.X[subset.indices]).float()\n",
    "        mean = X_train.mean(dim=(0, 1), keepdim=True)\n",
    "        std  = X_train.std(dim=(0, 1), keepdim=True).clamp_min(1e-6)\n",
    "        return mean, std\n",
    "\n",
    "    mean, std = compute_train_stats(train_ds)\n",
    "\n",
    "    # ÏõêÎ≥∏ train_dsÏùò Ïù∏Îç±Ïä§ÏôÄ ÎùºÎ≤® Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "    original_train_indices = train_ds.indices\n",
    "    original_train_labels = full_ds.y[original_train_indices]\n",
    "\n",
    "    # imblearnÏùÄ (n_samples, n_features) ÌòïÌÉúÎ•º Í∏∞ÎåÄÌï©ÎãàÎã§.\n",
    "    # XÎäî Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏïÑÎãàÎùº, ÎÇòÏ§ëÏóê Ïù∏Îç±Ïä§Î•º Îã§Ïãú ÎΩëÍ∏∞ ÏúÑÌïú \"ÏúÑÏπò ÌôÄÎçî\"ÏûÖÎãàÎã§.\n",
    "    # (ÏÉòÌîå Ïàò, 1) ÌÅ¨Í∏∞Ïùò Ïù∏Îç±Ïä§ Î∞∞Ïó¥ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "    X_indices_placeholder = np.arange(len(original_train_indices)).reshape(-1, 1)\n",
    "    y_labels = original_train_labels\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    # X_indices_placeholderÎ•º ÏÉòÌîåÎßÅÌï©ÎãàÎã§.\n",
    "    resampled_local_indices, _ = rus.fit_resample(X_indices_placeholder, y_labels)\n",
    "    \n",
    "    # resampled_local_indicesÎäî 0 ~ (N-1) ÏÇ¨Ïù¥Ïùò *Î°úÏª¨ Ïù∏Îç±Ïä§*ÏûÖÎãàÎã§.\n",
    "    # Ïù¥Î•º full_dsÏóê ÎåÄÌïú *Ïã§Ï†ú(Í∏ÄÎ°úÎ≤å) Ïù∏Îç±Ïä§*Î°ú Îã§Ïãú Îß§ÌïëÌï©ÎãàÎã§.\n",
    "    resampled_global_indices = np.array(original_train_indices)[resampled_local_indices.flatten()]\n",
    "    \n",
    "    print(f\"Resampled train samples: {len(resampled_global_indices)}\")\n",
    "    \n",
    "    # (ÏÑ†ÌÉù ÏÇ¨Ìï≠) ÎùºÎ≤® Î∂ÑÌè¨ ÌôïÏù∏\n",
    "    print(\"\\nOriginal label distribution (Train):\")\n",
    "    print(pd.Series(original_train_labels).value_counts().sort_index())\n",
    "    print(\"\\nResampled label distribution (Train):\")\n",
    "    print(pd.Series(full_ds.y[resampled_global_indices]).value_counts().sort_index())\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # ‚òÖ Ïñ∏ÎçîÏÉòÌîåÎßÅÎêú Ïù∏Îç±Ïä§Î°ú *ÏÉàÎ°úÏö¥* ÌïôÏäµÏö© Subset ÏÉùÏÑ±\n",
    "    train_ds = Subset(full_ds, resampled_global_indices)\n",
    "\n",
    "\n",
    "    def make_loaders(train_ds, test_ds, mean, std, batch_size=64, seed=42):\n",
    "        def collate_norm(batch):\n",
    "            X, y, s = zip(*batch)\n",
    "            X = torch.stack(X, dim=0).float()      # (B, T, C)\n",
    "            X = (X - mean) / std                   # ‚òÖ WISDMÎèÑ z-score Ï†ïÍ∑úÌôî\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "            s = torch.tensor(s, dtype=torch.long)\n",
    "            return X, y, s\n",
    "\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_ds, batch_size=batch_size, shuffle=True,\n",
    "            generator=g, num_workers=0, drop_last=True,\n",
    "            pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_ds, batch_size=batch_size, shuffle=False,\n",
    "            num_workers=0, drop_last=False,\n",
    "            pin_memory=torch.cuda.is_available(), collate_fn=collate_norm\n",
    "        )\n",
    "        return train_loader, test_loader\n",
    "\n",
    "    train_loader, test_loader = make_loaders(train_ds, test_ds, mean, std, seed=42)\n",
    "    \n",
    "    EPOCHS = 150 # Í≥µÌÜµ Epoch\n",
    "    N_CLASSES = len(np.unique(full_ds.y))\n",
    "    results = {} # Í≤∞Í≥º Ï†ÄÏû• ÎîïÏÖîÎÑàÎ¶¨\n",
    "\n",
    "    # ---\n",
    "    # üî¨ 1. New Base (n_layers=3, Multi-scale, No SE, No Physics)\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 1: Base (n_layers=3, Multi-scale, No SE)\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    \n",
    "    model1 = BaseModernTCNHAR(\n",
    "        input_dim=3, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.5,\n",
    "        use_se=False         # ‚≠êÔ∏è SE OFF\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model1)}\")\n",
    "    f1_1, acc_1 = train_base(model1, train_loader, test_loader, device, epochs=EPOCHS, model_name=\"Model 1 (Base, L=3)\")\n",
    "    results['1. Base (L=3, Multi)'] = {'f1': f1_1, 'acc': acc_1}\n",
    "\n",
    "    # ---\n",
    "    # üî¨ 2. + SE Block\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 2: + SE Block\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    train_loader, test_loader = make_loaders(train_ds, test_ds, mean, std, seed=42)\n",
    "    model2 = BaseModernTCNHAR(\n",
    "        input_dim=3, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.5,\n",
    "        use_se=True          # ‚≠êÔ∏è SE ON\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model2)}\")\n",
    "    f1_2, acc_2 = train_base(model2, train_loader, test_loader, device, epochs=EPOCHS, model_name=\"Model 2 (+SE)\")\n",
    "    results['2. + SE Block'] = {'f1': f1_2, 'acc': acc_2}\n",
    "    \n",
    "    # ---\n",
    "    # üî¨ 3. + Physics Loss (Full Model)\n",
    "    # ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üî¨ Ablation 3: + SE Block + Physics Loss\")\n",
    "    print(\"=\"*60)\n",
    "    set_seed(42)\n",
    "    train_loader, test_loader = make_loaders(train_ds, test_ds, mean, std, seed=42)\n",
    "    model3 = PhysicsModernTCNHAR( # ‚≠êÔ∏è Physics Î™®Îç∏ ÏÇ¨Ïö©\n",
    "        input_dim=3, hidden_dim=64, n_layers=3, # ‚≠êÔ∏è n_layers=2\n",
    "        n_classes=N_CLASSES,\n",
    "        kernel_sizes=[3, 7], # ‚≠êÔ∏è Multi-scale Ïú†ÏßÄ\n",
    "        large_kernel=19, \n",
    "        dropout=0.5,\n",
    "        use_se=True          # ‚≠êÔ∏è SE ON\n",
    "    ).to(device)\n",
    "    print(f\"  - Parameters: {get_n_params(model3)}\")\n",
    "    f1_3, acc_3, hist, best_state, best_eval = train_physics(model3, train_loader, test_loader, device, N_CLASSES,\n",
    "                                      epochs=EPOCHS, lambda_phys=0.05, log_every=25) # ‚≠êÔ∏è train_physics ÏÇ¨Ïö©\n",
    "    results['3. + Physics Loss'] = {'f1': f1_3, 'acc': acc_3}\n",
    "\n",
    "    plot_results(results)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (har-cu126)",
   "language": "python",
   "name": "har-cu126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
